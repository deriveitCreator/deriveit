export const title="deriving the regression coefficient of y on x";
const content = [['h1', 'Deriving The Regression Coefficient Of y On x'], ['pmain', 'Lets say we are given some x values with their associated y values:'], ['displayimg', '1.png'], ['pmain', 'We can take a guess at what the best fit line could look like:'], ['displayimg', '2.png'], ['pmain', 'Let y<sub>i</sub> be the output with x<sub>i</sub>, and let h<sub>i</sub> be the predicted output (= (&theta; * x<sub>i</sub>) + &alpha;, where &theta; is the gradient of the best fit line and &alpha; is the bias).'], ['displayimg', '3.PNG'], ['pmain', 'We will introduce another variable: <b>loss</b>, which is the sum of (y<sub>i</sub> - h<sub>i</sub>)<sup>2</sup>.'], ['displayimg', '4.PNG'], ['pmain', 'The smaller the difference between y<sub>i</sub> and h<sub>i</sub>, the smaller the value of loss. Our goal is to find the &theta; which will give the smallest possible value for loss. We can start by differentiating the loss with respect to &theta;, but before we do that, we must first expand &alpha;:'], ['displayimg', '5.PNG'], ['pmain', 'In the above equation, y<sub>m</sub> represents the mean y value, and x<sub>m</sub> represents the mean x value. The line of best fit is expected to pass through (x<sub>m</sub>, y<sub>m</sub>), meaning y<sub>m</sub> = &theta;x<sub>m</sub> + &alpha;. Now lets differentiate the loss:'], ['displayimg', '6.PNG'], ['pmain', 'With different values of &theta;, we get different values of loss. The loss function (with respect to &theta;) is a parabola, and to find the global minimum, we can set the gradient to 0.'], ['displayimg', '7.PNG'], ['pmain', 'We can simplify this:'], ['displayimg', '8.PNG'], ['pmain', 'Now lets make &theta; the subject:'], ['displayimg', '9.PNG'], ['pmain', 'This will give us the regression coefficient:'], ['displayimg', '10.PNG']];
export default content;